# Genetic Prompt Evolution with Delphi Evaluation
# Configuration for evolving both expert and mediator prompts using full Delphi process

experiment:
  name: "genetic_evolution_delphi"
  seed: 42
  output_dir: "results/genetic_evolution_delphi"
  initial_forecasts_dir: "initial_forecasts"
  
  # Reuse existing initial forecasts if available
  reuse_initial_forecasts:
    enabled: true
    source_dir: "auto"  # Auto-find matching forecasts
  
data:
  resolution_date: "2025-07-21"
  sampling:
    method: "train"  
  filters:
    require_resolution: true

model:
  expert:
    provider: "groq"
    model: "openai/gpt-oss-20b"        # Expert model
    temperature: 0.2
    max_tokens: 6000
    prompt_version: "v1"
  
  mediator:
    provider: "groq"
    model: "openai/gpt-oss-20b"        # Mediator model
    temperature: 0.2
    max_tokens: 6000
  
  learner:
    provider: "groq"
    model: "openai/gpt-oss-20b"        # Model used for LLM-based mutations
    temperature: 0.2    
    max_tokens: 6000

# Genetic algorithm configuration
evolution:
  population_size: 6         # Number of prompts in population (smaller for Delphi evaluation)
  max_generations: 15        # Fewer generations due to slower evaluation
  elitism_size: 2            # Top prompts preserved each generation
  tournament_size: 3         # Tournament selection size
  initial_mutation_rate: 0.5 # Starting mutation probability
  
  # Fitness evaluation settings
  fitness:
    # DELPHI EVALUATION SETTINGS
    use_delphi_evaluation: true          # Use full Delphi process for fitness evaluation
    optimize_component: "expert"         # Options: "expert", "mediator", "both"
    
    # Standard fitness settings
    length_penalty_weight: 0.05          # Smaller penalty for Delphi evaluation
    target_length: 100                   # Target prompt length in tokens
    superforecaster_examples_file: null  # Path to JSON file with superforecaster examples
    include_reasoning: true              # Include superforecaster reasoning template
    include_examples: false              # Include ICL examples
    n_examples: 3                       # Number of ICL examples to include

# Delphi configuration for evaluation
delphi:
  n_rounds: 2              # Short Delphi rounds for fitness evaluation
  n_experts: 3             # Fewer experts for faster evaluation
  expert_selection: "random"
  expert_selection_seed: 42

# Training configuration  
training:
  valid_ratio: 0.3              # Fraction of data for validation
  validation_batch_size: 3      # SMALL batch size for Delphi evaluation

# Processing options
processing:
  skip_existing: false          # Whether to skip if results already exist
  max_concurrent: 2             # Lower concurrency for Delphi evaluation
  max_concurrent_mutations: 2   # Lower concurrent mutations
  retry_attempts: 2             # Retries for failed predictions

# Output settings
output:
  save:
    conversation_histories: false       # Don't save histories during evolution
    example_pairs: false
  file_pattern: "genetic_delphi_{question_id}_{resolution_date}.json"

# API configuration  
api:
  openai:
    api_key_env: "OPENAI_API_KEY"
  groq:
    api_key_env: "GROQ_API_KEY"