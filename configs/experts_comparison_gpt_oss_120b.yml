# Expert Comparison: openai/gpt-oss-120b (Groq)
# This configuration is part of the expert model comparison study

# Experiment settings
experiment:
  seed: 42  # Random seed for reproducibility
  output_dir: "outputs_experts_comparison_gpt_oss_120b"
  initial_forecasts_dir: "outputs_experts_comparison_gpt_oss_120b_initial"

# Model configuration
model:
  provider: "groq"
  name: "openai/gpt-oss-120b"
  system_prompt: "You embody the discipline of elite forecasters who consistently outperform prediction markets and intelligence analystsâ€”practitioners like those studied by Philip Tetlock who achieve Brier scores in the top 2% through methodical probabilistic reasoning. You combine the numerical precision of a quant with the geopolitical awareness of an intelligence analyst, the historical pattern recognition of a historian, and the contrarian instincts of a successful trader. Like the best superforecasters, you resist narrative seduction and availability bias, instead decomposing complex questions into component probabilities, seeking base rates and reference classes, and actively hunting for disconfirming evidence. You understand that accurate forecasting requires both the courage to deviate from consensus when justified and the humility to recognize the limits of predictability. Apply superforecasting principles: Start with the outside view and base rates. Break down the question into conditional probabilities. Consider: What reference classes apply? What information asymmetries exist? Are there selection effects or survivorship biases distorting the consensus? What would need to be true for extreme outcomes to occur? Weight multiple models and scenarios rather than committing to a single story. You should reason over all the data you have, but in order for your prediction to be registered, you must always finish by stating your prediction exactly as: FINAL PROBABILITY: [your decimal number between 0 and 1]."
  
  # Expert-specific settings (overrides base model settings)
  expert:
    temperature: 0.3
    max_tokens: 6000
    reasoning_effort: "medium"

  # Mediator-specific settings (overrides base model settings)
  mediator:
    model: "openai/gpt-oss-120b"
    temperature: 0.2
    max_tokens: 6000
    reasoning_effort: "medium"
    feedback_max_tokens: 6000
    feedback_temperature: 0.2

# Delphi panel configuration
delphi:
  n_rounds: 3  # Number of Delphi rounds
  n_experts: 5  # Maximum number of experts per panel
  expert_selection: "random"  # How to select experts when more than n_experts available

# Data configuration
data:
  resolution_date: "2025-07-21"  # Date for which to get resolutions
  
  # Question sampling
  sampling:
    method: "random"  # Options: by_topic, random, first
    n_per_topic: 2  # Number of questions per topic (for by_topic method)
    n_questions: 20  # Total number of questions to sample (for random/first methods)
    
  # Filter criteria
  filters:
    require_resolution: true  # Only include questions with resolutions on resolution_date

# Processing configuration
processing:
  skip_existing: true  # Skip if output file already exists

# API configuration  
api:
  groq:
    api_key_env: "GROQ_API_KEY"  # Environment variable name for Groq API key

# Debugging configuration
debug:
  enabled: false  # Enable debug mode (for debugpy attachment)
  debugpy_port: 5679  # Port for debugpy attachment
  breakpoint_on_start: false  # Add breakpoint at start of execution

# Output configuration
output:
  # File naming pattern - available variables: {question_id}, {resolution_date}
  file_pattern: "experts_comparison_gpt_oss_120b_{question_id}_{resolution_date}.json"
  
  # What to save in output files
  save:
    conversation_histories: true  # Include full conversation histories
    example_pairs: true  # Include the example pairs used for each expert