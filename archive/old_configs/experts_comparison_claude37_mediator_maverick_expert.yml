# Expert Comparison: o3-2025-04-16 (OpenAI)
# This configuration is part of the expert model comparison study

# Experiment settings
experiment:
  seed: 42  # Random seed for reproducibility
  output_dir: "results/experts_comparison_o3"
  initial_forecasts_dir: "results/experts_comparison_o3_initial"

  reuse_initial_forecasts:
    enabled: true
    source_dir: "auto"  # Automatically find the latest initial forecasts directory

model:
  provider: "openai"
  name: "o3-2025-04-16"
  system_prompt: "You are a superforecaster. Take a bold, distinctive position. Avoid consensus thinking and consider extreme scenarios. \n\nWhen making a prediction, you should write one or more paragraphs in prose that present your analysis, but you must always conclude with:\n\n```\nFINAL PROBABILITY: [decimal between 0 and 1]\n```" 
  
  # Expert-specific settings (overrides base model settings)
  expert:
    provider: "groq"
    model: "meta-llama/llama-4-maverick-17b-128e-instruct"
    temperature: 0.3
    max_tokens: 6000
    
  # Mediator-specific settings (overrides base model settings)
  mediator:
    provider: "anthropic"
    model: "claude-3-7-sonnet-20250219"
    temperature: 0.2
    max_tokens: 6000
    feedback_max_tokens: 6000
    feedback_temperature: 0.2

# Delphi panel configuration
delphi:
  n_rounds: 3  # Number of Delphi rounds
  n_experts: 5  # Maximum number of experts per panel
  expert_selection: "random"  # How to select experts when more than n_experts available
  expert_selection_seed: 42  # Fixed seed for expert selection (independent of experiment seed)

# Data configuration
data:
  resolution_date: "2025-07-21"  # Date for which to get resolutions
  

  # # Question sampling
  # Sampling configuration - this will be based on what's available in the reused forecasts
  sampling:
    method: "from_initial_forecasts"  # Special method for reusing
    n_questions: 30
  # Filter criteria
  filters:
    require_resolution: true  # Only include questions with resolutions on resolution_date

# Processing configuration
processing:
  skip_existing: true  # Skip if output file already exists

# API configuration  
api:
  openai:
    api_key_env: "OPENAI_API_KEY"  # Environment variable name for API key

# Debugging configuration
debug:
  enabled: false  # Enable debug mode (for debugpy attachment)
  debugpy_port: 5679  # Port for debugpy attachment
  breakpoint_on_start: false  # Add breakpoint at start of execution

# Output configuration
output:
  # File naming pattern - available variables: {question_id}, {resolution_date}
  file_pattern: "experts_comparison_o3_{question_id}_{resolution_date}.json"
  
  # What to save in output files
  save:
    conversation_histories: true  # Include full conversation histories
    example_pairs: true  # Include the example pairs used for each expert